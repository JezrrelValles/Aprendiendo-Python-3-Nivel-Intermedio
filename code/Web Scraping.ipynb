{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping con BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Instalar e importar librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Enviar petición HTTP para extraer código fuente de la página web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagina_web = requests.get('http://books.toscrape.com/')\n",
    "\n",
    "soup = BeautifulSoup(pagina_web.text, 'html.parser')\n",
    "\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analizar código fuente resultante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Extrae la información relevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulo_item = soup.find('a')\n",
    "\n",
    "print(titulo_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulo_items = soup.find_all('a')\n",
    "\n",
    "print(titulo_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulos = []\n",
    "links = []\n",
    "\n",
    "titulo_items = soup.find_all('h3')\n",
    "\n",
    "for items in titulo_items:\n",
    "    titulo = items.a\n",
    "    titulos.append(titulo['title'])\n",
    "    links.append(titulo['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precios = []\n",
    "\n",
    "precio_items = soup.find_all('p', class_=\"price_color\")\n",
    "\n",
    "for item in precio_items:\n",
    "    precio = item.text\n",
    "    precios.append(precio.lstrip(\"Â£\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "existencias = []\n",
    "\n",
    "existencia_items = soup.find_all('p', class_='instock availability')\n",
    "\n",
    "for item in existencia_items:\n",
    "    existencia = item.text.strip()\n",
    "    existencias.append(existencia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "existencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = []\n",
    "\n",
    "rating_items = soup.find_all('p', class_=\"star-rating\")\n",
    "\n",
    "for item in rating_items:\n",
    "    rating = item['class'][1]\n",
    "    ratings.append(rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'Titulo': titulos,\n",
    "    'Precio': precios,\n",
    "    'Rating': ratings,\n",
    "    'En existencia': existencias,\n",
    "    'Links': links\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulos = []\n",
    "links = []\n",
    "\n",
    "titulo_items = soup.find_all('h3')\n",
    "\n",
    "for items in titulo_items:\n",
    "    titulo = items.a\n",
    "    titulos.append(titulo['title'])\n",
    "    links.append(\"http://books.toscrape.com/\" + titulo['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Precio'] = df['Precio'].apply(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Precio'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Precio'].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paginación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_contenido_pagina(url):\n",
    "    response = requests.get(url)\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analizar_contenido_html(html):\n",
    "    return BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "def procesar_pagina(soup):\n",
    "    titulos = []\n",
    "    links = []\n",
    "    ratings = []\n",
    "    existencias = []\n",
    "\n",
    "    titulo_items = soup.find_all('h3')\n",
    "\n",
    "    for items in titulo_items:\n",
    "        titulo = items.a\n",
    "        titulos.append(titulo['title'])\n",
    "        links.append(titulo['href'])\n",
    "\n",
    "    rating_items = soup.find_all('p', class_=\"star-rating\")\n",
    "\n",
    "    for item in rating_items:\n",
    "        rating = item['class'][1]\n",
    "        ratings.append(rating)\n",
    "\n",
    "    existencia_items = soup.find_all('p', class_='instock availability')\n",
    "\n",
    "    for item in existencia_items:\n",
    "        existencia = item.text.strip()\n",
    "        existencias.append(existencia)\n",
    "\n",
    "    for i in range(len(titulos)):\n",
    "        data.append({\n",
    "            \"Título\": titulos[i],\n",
    "            \"Enlace\": links[i],\n",
    "            \"Rating\": ratings[i],\n",
    "            \"Existencia\": existencias[i]\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manejar_paginacion(url_base, num_paginas):\n",
    "    for i in range(1, num_paginas + 1):\n",
    "        url = url_base + '/page-' + str(i) + \".html\"  # Actualiza la URL base con el número de página actual\n",
    "        contenido_pagina = obtener_contenido_pagina(url)\n",
    "        soup = analizar_contenido_html(contenido_pagina)\n",
    "        procesar_pagina(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_base = 'http://books.toscrape.com/catalogue/category/books_1/'  # Reemplaza con tu URL base\n",
    "num_paginas = 50  # Reemplaza con el número total de páginas\n",
    "\n",
    "manejar_paginacion(url_base, num_paginas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get('https://www.cyberpuerta.mx/Promociones/')\n",
    "\n",
    "soup = BeautifulSoup(page.text, 'html.parser')\n",
    "\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_items = soup.find('div', class_=\"emproduct_right\")\n",
    "\n",
    "print(lista_items.div)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_items = soup.find('div', class_=\"emproduct_right\")\n",
    "\n",
    "print(lista_items.a.attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_items = soup.find('div', class_=\"emproduct_right\")\n",
    "\n",
    "print(lista_items.a['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_items = soup.find_all('div', class_=\"emproduct_right\")\n",
    "\n",
    "print(lista_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = []\n",
    "\n",
    "for i in range(1, 10):\n",
    "    response = requests.get(f'http://books.toscrape.com/catalogue/category/books/young-adult_21/page-{i}.html')\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        urls.append(response.url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulos = []\n",
    "\n",
    "def extraer_titulos(soup):\n",
    "    page_items = soup.find_all('h3')\n",
    "\n",
    "    for item in page_items:\n",
    "        etiqueta = item.find('a')\n",
    "        titulo = etiqueta['title']\n",
    "        titulos.append(titulo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precios = []\n",
    "\n",
    "def extraer_precios(soup):\n",
    "    page_items = soup.find_all('p', class_=\"price_color\")\n",
    "\n",
    "    for item in page_items:\n",
    "        precio = item.text\n",
    "        precios.append(precio)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = []\n",
    "\n",
    "def extraer_ratings(soup):\n",
    "    page_items = soup.find_all('p', class_=\"star-rating\")\n",
    "\n",
    "    for item in page_items:\n",
    "        ratings.append(item['class'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "existencias = []\n",
    "\n",
    "def extraer_existencias(soup):\n",
    "    page_items = soup.find_all('p', class_=\"instock availability\")\n",
    "\n",
    "    for item in page_items:\n",
    "        existencia = item.text\n",
    "        existencias.append(existencia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_contenido_titulos(url):\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    extraer_titulos(soup)\n",
    "    extraer_precios(soup)\n",
    "    extraer_ratings(soup)\n",
    "    extraer_existencias(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in urls:\n",
    "    obtener_contenido_titulos(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {'Titulo': titulos, 'Precio': precios, 'Rating': ratings, 'En existencia': existencias}\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
